{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba de evaluación 2\n",
    "\n",
    "Realizado por Araceli Macía Barrado\n",
    "\n",
    "## Parte 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El sitio Web NOOA del gobierno de EEUU proporciona datasets de datos climáticos a través de esta página Web:\n",
    "http://www.ncdc.noaa.gov/cdo-web/datasets\n",
    "\n",
    "    \n",
    "Entre ellos tenemos los datasets “Quality Controlled Local Climatological Data (QCLCD)” que se describen aquí: http://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based- datasets/quality-controlled-local-climatological-data-qclcd\n",
    "\n",
    "Entre los datos que se encuentran en los datasets QCLCD están las precipitaciones por años y estaciones. Por ejemplo, podemos descargar los datasets de aquí:\n",
    "\n",
    "http://www.ncdc.noaa.gov/orders/qclcd/\n",
    "\n",
    "Y encontraremos ficheros con datos de precipitaciones como este:\n",
    "Wban Number, YearMonthDay, Time, Hourly Precip 03013,19960701,0053,0\n",
    "03013,19960701,0153,0\n",
    "03013,19960701,0253,0\n",
    "03013,19960701,0353,0 03013,19960701,0453,0 ...\n",
    "\n",
    "Se pide tomar datos de varios años (queda a la elección del estudiante) de este conjunto de datasets para las precipitaciones y obtener los siguientes resúmenes:\n",
    "\n",
    "- Día en que ha habido más precipitaciones.\n",
    "- Año en que ha habido más precipitaciones (obteniendo la media de cada año) \n",
    "\n",
    "\n",
    "Se pide realizar el análisis en dos versiones:\n",
    "- Una utilizando DataFrames y los ficheros de texto que se decargan directamente.\n",
    "- Una segunda con un paso previo en el que se guardan los datos en un fichero HDF5 (que debe contener los metadatos descriptivos necesarios). Queda a la decisión del estudiante cómo organizar los datos en el fichero.\n",
    "\n",
    "Y se pide comparar:\n",
    "- El tamaño en disco que ocupan los datos en cada una de las versiones. - El tiempo comparado de ejecución de los resúmenes anteriores.\n",
    "\n",
    "Opcional: finalmente, se platea el almacenar en el fichero HDF5 los resúmenes mismos obtenidos y comparar el tiempo de recuperación de esos datos del fichero con el tiempo tardado en calcularlo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "Para la realizacion de la practica me he bajado los ficheros del mes de Abril de los año 2012 al 2016.\n",
    "Los tengo en la carpeta datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Una utilizando DataFrames y los ficheros de texto que se decargan directamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import cProfile\n",
    "\n",
    "def str2f(x):\n",
    "    \n",
    "    x1=str(x)[0:4]\n",
    "    x1= x1.strip(\" \")                       \n",
    "    if x1=='M' or x1.strip()=='T' or x1==\"\" or x1==\"TE\":       \n",
    "        return float(\"0\")              \n",
    "    else:  \n",
    "        return float(x1)\n",
    "\n",
    "def sstring(x):\n",
    "    return str(x)\n",
    "\n",
    "ficheros= glob.glob(\"datos/*.txt\") #almaceno todos los nombres de los ficheros txt que tengo en el directorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "dataTotal=pd.DataFrame()\n",
    "filas=0\n",
    "for fic in ficheros:\n",
    "    data1= pd.read_csv(fic,index_col=None, header=0, usecols=[\"YearMonthDay\", \"Precipitation\"],\\\n",
    "                       converters={'Precipitation':str2f, 'YearMonthDay':sstring}) \n",
    "    filas=filas+ data1.shape[0]\n",
    "    dataTotal=dataTotal.append(data1,ignore_index=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero de filas 7643520\n",
      "(7643520, 2)\n",
      "        YearMonthDay  Precipitation\n",
      "7643519     20160430            0.0\n"
     ]
    }
   ],
   "source": [
    "print \"numero de filas\" , filas  #reviso que tengo todas las filas y que el indice ha quedado bien\n",
    "print dataTotal.shape\n",
    "print dataTotal.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: lluvias.csv: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "#para poder comparar el tamaño, voy a volcar el dataframe resultante a un csv\n",
    "%rm lluvias.csv\n",
    "dataTotal.to_csv('lluvia.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora voy a revisar los datos que se han cargado en YearMonthDay y PrecipTotal que son los valores que me interesan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['20120401', '20120402', '20120403', '20120404', '20120405',\n",
       "       '20120406', '20120407', '20120408', '20120409', '20120410',\n",
       "       '20120411', '20120412', '20120413', '20120414', '20120415',\n",
       "       '20120416', '20120417', '20120418', '20120419', '20120420',\n",
       "       '20120421', '20120422', '20120423', '20120424', '20120425',\n",
       "       '20120426', '20120427', '20120428', '20120429', '20120430',\n",
       "       '20130401', '20130402', '20130403', '20130404', '20130405',\n",
       "       '20130406', '20130407', '20130408', '20130409', '20130410',\n",
       "       '20130411', '20130412', '20130413', '20130414', '20130415',\n",
       "       '20130416', '20130417', '20130418', '20130419', '20130420',\n",
       "       '20130421', '20130422', '20130423', '20130424', '20130425',\n",
       "       '20130426', '20130427', '20130428', '20130429', '20130430',\n",
       "       '20140401', '20140402', '20140403', '20140404', '20140405',\n",
       "       '20140406', '20140407', '20140408', '20140409', '20140410',\n",
       "       '20140411', '20140412', '20140413', '20140414', '20140415',\n",
       "       '20140416', '20140417', '20140418', '20140419', '20140420',\n",
       "       '20140421', '20140422', '20140423', '20140424', '20140425',\n",
       "       '20140426', '20140427', '20140428', '20140429', '20140430',\n",
       "       '20150401', '20150402', '20150403', '20150404', '20150405',\n",
       "       '20150406', '20150407', '20150408', '20150409', '20150410',\n",
       "       '20150411', '20150412', '20150413', '20150414', '20150415',\n",
       "       '20150416', '20150417', '20150418', '20150419', '20150420',\n",
       "       '20150421', '20150422', '20150423', '20150424', '20150425',\n",
       "       '20150426', '20150427', '20150428', '20150429', '20150430',\n",
       "       '20160401', '20160402', '20160403', '20160404', '20160405',\n",
       "       '20160406', '20160407', '20160408', '20160409', '20160410',\n",
       "       '20160411', '20160412', '20160413', '20160414', '20160415',\n",
       "       '20160416', '20160417', '20160418', '20160419', '20160420',\n",
       "       '20160421', '20160422', '20160423', '20160424', '20160425',\n",
       "       '20160426', '20160427', '20160428', '20160429', '20160430'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTotal['YearMonthDay'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2012' '2013' '2014' '2015' '2016']\n"
     ]
    }
   ],
   "source": [
    "dataTotal[\"anio\"]=dataTotal[\"YearMonthDay\"].str[0:4]\n",
    "print dataTotal.anio.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De los datos que hay, no voy a considerar los que tienen que lluvia ha sido 0, porque desvirtuaria los calculos de las precipitaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 419 ms, sys: 117 ms, total: 536 ms\n",
      "Wall time: 571 ms\n",
      "(367919, 3)\n"
     ]
    }
   ],
   "source": [
    "%time dataTratar=dataTotal.loc[dataTotal[\"Precipitation\"]>0]\n",
    "print dataTratar.shape  #el numero de registros a tratar ha bajado considerablemente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Dia en que ha habido mas precipitaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.12 ms, sys: 1.12 ms, total: 5.24 ms\n",
      "Wall time: 3.77 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YearMonthDay</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>anio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7002973</th>\n",
       "      <td>20160411</td>\n",
       "      <td>11.5</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        YearMonthDay  Precipitation  anio\n",
       "7002973     20160411           11.5  2016"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time  dataTratar[dataTratar[\"Precipitation\"]==dataTratar[\"Precipitation\"].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **el dia que hubo mas precipitaciones fue el 11 de abril de 2016.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Año en que ha habido mas precipitaciones obteniendo la media por año"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "anio\n",
       "2012    0.064002\n",
       "2013    0.064294\n",
       "2014    0.067134\n",
       "2015    0.072001\n",
       "2016    0.070388\n",
       "Name: Precipitation, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anioMax=dataTratar.groupby(\"anio\")\n",
    "anioMax[\"Precipitation\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2015'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anioMax[\"Precipitation\"].mean().argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **El año 2015 fue el que tuvo el mes de abril mas lluvioso.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "\n",
    "###  Con paso previo, guardando los datos en un fichero HDF5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%rm lluvia.hdf5\n",
    "#store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7643520, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'pandas.io.pytables.HDFStore'>\n",
       "File path: lluvia.hdf5\n",
       "/DTTotales            frame_table  (typ->appendable,nrows->7643520,ncols->2,indexers->[index])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import tables as tb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import cProfile\n",
    "\n",
    "def str2f(x):\n",
    "    \n",
    "    x1=str(x)[0:4]\n",
    "    x1= x1.strip(\" \")                       \n",
    "    if x1=='M' or x1.strip()=='T' or x1==\"\" or x1==\"TE\":       \n",
    "        return float(\"0\")              \n",
    "    else:  \n",
    "        return float(x1)\n",
    "\n",
    "def sstring(x):\n",
    "    return str(x)\n",
    "\n",
    "ficheros= glob.glob(\"datos/*.txt\") #almaceno todos los nombres de los ficheros txt que tengo en el directorio.\n",
    "\n",
    "lines = 50000 #se suben en chunk de 5000 lineas.\n",
    "store = pd.HDFStore('lluvia.hdf5',mode='w')\n",
    "\n",
    "#En el fichero h5 almaceno los datos por año.\n",
    "for fic in ficheros:  \n",
    "    for chunk in pd.read_csv(fic, chunksize=lines, \\\n",
    "                         index_col=None, header=0, usecols=[\"YearMonthDay\", \"Precipitation\"],converters={'Precipitation':str2f, 'YearMonthDay':sstring}): \n",
    "\n",
    "        nom=\"DTTotales\"\n",
    "        store.append(nom,chunk)\n",
    "        store.get_storer(nom).attrs.descripcion=\"Datos de Abril de 2012,2013,2014,2015 y 2016\"  #inserto atributos\n",
    "        store.get_storer(nom).attrs.fechaDatos=\"20161014\"\n",
    "\n",
    "print store.select(\"DTTotales\").shape\n",
    "store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "el numero de filas 7643520 coincide. Se ha hecho la carga correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Dia en que ha habido mas precipitaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.4 s, sys: 2.51 s, total: 5.91 s\n",
      "Wall time: 7.27 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YearMonthDay</th>\n",
       "      <th>Precipitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28413</th>\n",
       "      <td>20160411</td>\n",
       "      <td>11.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      YearMonthDay  Precipitation\n",
       "28413     20160411           11.5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time  store.select(\"DTTotales\")[store.select(\"DTTotales\")[\"Precipitation\"]==store.select(\"DTTotales\")[\"Precipitation\"].max()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> El dia que hubo mas precipitaciones, el 11 de Abril del 2016\n",
    "\n",
    "**Comparando el tiempo de ejecucion con la instruccion arriba ejecutada:**\n",
    "\n",
    "%time  dataTratar[dataTratar[\"Precipitation\"]==dataTratar[\"Precipitation\"].max()]\n",
    "\n",
    "**se aprecia que el tiempo en realizar esta ejecucion ha sido <font color=\"red\"> mayor </font>, puesto que en esta lectura los datos estan en disco.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Año en que ha habido mas precipitaciones obteniendo la media por año"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.84 s, sys: 1.3 s, total: 3.14 s\n",
      "Wall time: 3.61 s\n"
     ]
    }
   ],
   "source": [
    "#Para hacer esto, tengo que pasar los datos un dataframe en memoria, si ejecuto las instrucciones directamente \n",
    "#en el store, tarda una eternidad..\n",
    "\n",
    "#store.select(\"DTTotales\").loc[store.select(\"DTTotales\")[\"Precipitation\"]>0].groupby(store.select(\"DTTotales\")[\"YearMonthDay\"].str[0:4])\n",
    "\n",
    "%time datosAtratar=store.select(\"DTTotales\").loc[store.select(\"DTTotales\")[\"Precipitation\"]>0] \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Comparando el tiempo de ejecucion con la instruccion arriba ejecutada:**\n",
    "\n",
    "%time dataTratar=dataTotal.loc[dataTotal[\"Precipitation\"]>0]\n",
    "\n",
    "**se aprecia que el tiempo en realizar esta ejecucion ha sido <font color=\"red\"> mucho mayor </font>, puesto que en esta lectura los datos estan en disco.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2012' '2013' '2014' '2015' '2016']\n"
     ]
    }
   ],
   "source": [
    "datosAtratar[\"anio\"]=datosAtratar[\"YearMonthDay\"].str[0:4]\n",
    "print datosAtratar.anio.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "anio\n",
       "2012    0.064002\n",
       "2013    0.064294\n",
       "2014    0.067134\n",
       "2015    0.072001\n",
       "2016    0.070388\n",
       "Name: Precipitation, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anioMax=datosAtratar.groupby(\"anio\")\n",
    "anioMax[\"Precipitation\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2015'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anioMax[\"Precipitation\"].mean().argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **El año 2015 fue el que tuvo el mes de abril mas lluvioso.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparar el tamaño en disco que ocupan los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 aramaciabarrado  staff  159759948 16 oct 17:35 lluvia.csv\r\n",
      "-rw-r--r--  1 aramaciabarrado  staff  192708058 16 oct 17:37 lluvia.hdf5\r\n"
     ]
    }
   ],
   "source": [
    "%ls -ltr lluvia*.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "el fichero h5df es mayor que el csv teniendo los dos el mismo  numero de filas y columnas.\n",
    "He estado revisando documentacion por internet, y tras ejecutar esta linea de comando:\n",
    "\n",
    " h5ls -vr /Users/aramaciabarrado/Documents/*.h5df \n",
    " \n",
    "me devuelve una serie de datos,  y al final acabo diciendo esto:\n",
    "\n",
    "in h5tools_dump_mem(): H5Sis_simple failed\n",
    "\n",
    "la compresion falla..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "### Revisar los tiempos de ejecucion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A) Comparar tiempo de lectura entre un fichero csv y un fichero h5df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Oct 16 17:38:11 2016    Times.log\n",
      "\n",
      "         715 function calls (708 primitive calls) in 3.974 seconds\n",
      "\n",
      "   Ordered by: file name\n",
      "   List reduced from 161 to 4 due to restriction <'read'>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    3.633    3.633 /Users/aramaciabarrado/anaconda/lib/python2.7/site-packages/pandas/io/parsers.py:1211(read)\n",
      "        1    0.012    0.012    3.789    3.789 /Users/aramaciabarrado/anaconda/lib/python2.7/site-packages/pandas/io/parsers.py:256(_read)\n",
      "        1    0.000    0.000    3.774    3.774 /Users/aramaciabarrado/anaconda/lib/python2.7/site-packages/pandas/io/parsers.py:758(read)\n",
      "        1    3.633    3.633    3.633    3.633 {method 'read' of 'pandas.parser.TextReader' objects}\n",
      "\n",
      "\n",
      "\n",
      "(7643520, 2)\n"
     ]
    }
   ],
   "source": [
    "import StringIO\n",
    "import pstats\n",
    "\n",
    "ficheros= glob.glob(\"datos/*.txt\") #almaceno todos los nombres de los ficheros txt que tengo en el directorio.\n",
    "dataTotal=pd.DataFrame()\n",
    "filas=0\n",
    "\n",
    "%rm Times.log\n",
    "pr = cProfile.Profile()\n",
    "pr.enable()\n",
    "#voy a leer el fichero lluvia.csv que es donde habia volcado el dataframe con todos los datos.\n",
    "data1 = pd.read_csv(\"lluvia.csv\", index_col=None, header=0, usecols=[\"YearMonthDay\", \"Precipitation\"])\n",
    "\n",
    "pr.disable()\n",
    "pr.dump_stats(\"Times.log\")\n",
    "s = StringIO.StringIO()\n",
    "sortby = 'filename'\n",
    "ps = pstats.Stats(\"Times.log\", stream=s).sort_stats(sortby)\n",
    "ps.print_stats(\"read\")\n",
    "print s.getvalue()\n",
    "\n",
    "print data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Oct 16 17:38:14 2016    Times.log\n",
      "\n",
      "         7471 function calls (7185 primitive calls) in 1.656 seconds\n",
      "\n",
      "   Ordered by: file name\n",
      "   List reduced from 666 to 13 due to restriction <'read'>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.000    0.000 /Users/aramaciabarrado/anaconda/lib/python2.7/site-packages/numexpr/utils.py:61(set_vml_num_threads)\n",
      "        6    0.000    0.000    0.000    0.000 /Users/aramaciabarrado/anaconda/lib/python2.7/site-packages/pandas/io/pytables.py:1630(read_metadata)\n",
      "        1    0.000    0.000    1.628    1.628 /Users/aramaciabarrado/anaconda/lib/python2.7/site-packages/pandas/io/pytables.py:4019(read)\n",
      "        1    0.000    0.000    1.653    1.653 /Users/aramaciabarrado/anaconda/lib/python2.7/site-packages/pandas/io/pytables.py:265(read_hdf)\n",
      "        6    0.000    0.000    0.000    0.000 /Users/aramaciabarrado/anaconda/lib/python2.7/site-packages/pandas/io/pytables.py:3037(read_metadata)\n",
      "        1    0.000    0.000    1.001    1.001 /Users/aramaciabarrado/anaconda/lib/python2.7/site-packages/pandas/io/pytables.py:3209(read_axes)\n",
      "        1    0.000    0.000    0.000    0.000 /Users/aramaciabarrado/anaconda/lib/python2.7/site-packages/tables/array.py:758(_read_slice)\n",
      "        1    0.000    0.000    0.276    0.276 /Users/aramaciabarrado/anaconda/lib/python2.7/site-packages/tables/table.py:1865(_read)\n",
      "        1    0.000    0.000    0.276    0.276 /Users/aramaciabarrado/anaconda/lib/python2.7/site-packages/tables/table.py:1937(read)\n",
      "        1    0.000    0.000    0.000    0.000 {tables.utilsextension.read_f_attr}\n",
      "        1    0.276    0.276    0.276    0.276 {method '_read_records' of 'tables.tableextension.Table' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {numexpr.interpreter._set_vml_num_threads}\n",
      "        1    0.000    0.000    0.000    0.000 {method '_g_read_slice' of 'tables.hdf5extension.Array' objects}\n",
      "\n",
      "\n",
      "\n",
      "(7643520, 2)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "from pandas import read_hdf\n",
    "\n",
    "\n",
    "\n",
    "%rm Times.log\n",
    "pr = cProfile.Profile()\n",
    "pr.enable()\n",
    "\n",
    "dataTotal=pd.DataFrame()\n",
    "hdf = read_hdf('lluvia.hdf5', \"DTTotales\")\n",
    "    \n",
    "pr.disable()\n",
    "pr.dump_stats(\"Times.log\")\n",
    "\n",
    "s = StringIO.StringIO()\n",
    "sortby = 'filename'\n",
    "ps = pstats.Stats(\"Times.log\", stream=s).sort_stats(sortby)\n",
    "ps.print_stats(\"read\")\n",
    "print s.getvalue()\n",
    "print hdf.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**El tiempo de recuperar los datos de un fichero hdf5 es significativamente mejor.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B) Comparar tiempo de escritura entre un fichero csv y un fichero h5df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%rm lluvia.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Oct 16 17:38:44 2016    Times.log\n",
      "\n",
      "         53525540 function calls in 24.744 seconds\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%rm Times.log\n",
    "pr = cProfile.Profile()\n",
    "pr.enable()\n",
    "data1.to_csv('lluvia.csv')\n",
    "pr.disable()\n",
    "pr.dump_stats(\"Times.log\")\n",
    "s = StringIO.StringIO()\n",
    "sortby = 'filename'\n",
    "ps = pstats.Stats(\"Times.log\", stream=s).sort_stats(sortby)\n",
    "ps.print_stats(\"calls\")\n",
    "print s.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Oct 16 17:38:53 2016    Times.log\n",
      "\n",
      "         302589 function calls (302560 primitive calls) in 5.040 seconds\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%rm Times.log\n",
    "%rm lluvia.hdf5\n",
    "pr = cProfile.Profile()\n",
    "pr.enable()\n",
    "\n",
    "store = pd.HDFStore('lluvia.hdf5',mode='w')\n",
    "store.append(\"DTTotales\",data1)\n",
    "store.close()\n",
    "\n",
    "pr.disable()\n",
    "pr.dump_stats(\"Times.log\")\n",
    "s = StringIO.StringIO()\n",
    "sortby = 'filename'\n",
    "ps = pstats.Stats(\"Times.log\", stream=s).sort_stats(sortby)\n",
    "ps.print_stats(\"calls\")\n",
    "print s.getvalue()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El tiempo de generar un fichero h5df es significativamente mejor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es decir, lo optimo es generar y leer datos en ficheros hf5 ( siempre que se pueda), y luego pasarlos a memoria para poder trabajar con ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
